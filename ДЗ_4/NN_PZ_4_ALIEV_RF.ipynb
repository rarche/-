{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "обучить рукописную сверточную нейронную сеть (с падением размера ядра свертки и последовательностью блоков свертка-пулинг (conv-pool)-(conv-pool)-...) на датасете cifar-10\n",
    "оценить рост точности при увеличении ширины сети (больше фильтров)\n",
    "оценить рост точности при увеличении глубины сети (больше слоев)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "import os\n",
    "\n",
    "# разделение тренировочной и тестовой выборки\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'тренировочные примеры')\n",
    "print(x_test.shape[0], 'тестовые примеры')\n",
    "\n",
    "# преобразование матрицы чисел 0-9 в бинарную матрицу чисел 0-1\n",
    "y_train = keras.utils.to_categorical(y_train, 10)\n",
    "y_test = keras.utils.to_categorical(y_test, 10)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "import os\n",
    "\n",
    "# разделение тренировочной и тестовой выборки\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'тренировочные примеры')\n",
    "print(x_test.shape[0], 'тестовые примеры')\n",
    "\n",
    "# преобразование матрицы чисел 0-9 в бинарную матрицу чисел 0-1\n",
    "y_train = keras.utils.to_categorical(y_train, 10)\n",
    "y_test = keras.utils.to_categorical(y_test, 10)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Функция, которая создает модель\n",
    "def create_model(conv_layers=[(4,5,2,2),(8,3,2,2)], \n",
    "                               dense_layers=[50], dropout=0.25):\n",
    "    print('model- conv_layers:', conv_layers, 'dense_layers:',dense_layers)\n",
    "    model = Sequential()\n",
    "    # Добавление слоя свертки\n",
    "    conv_layers_count = 0\n",
    "    for (filters, kernel_size, pooling_size, pool_stride) in conv_layers:\n",
    "        conv_layers_count += 1\n",
    "        if 1 == conv_layers_count:\n",
    "            # Параметры для первого слоя свертки\n",
    "            model.add(Conv2D(filters, \n",
    "                           (kernel_size, kernel_size), \n",
    "                           strides=(1, 1), \n",
    "                           activation='relu',\n",
    "                           padding='same', \n",
    "                           input_shape=(32, 32, 3)))\n",
    "            model.add(Conv2D(filters, \n",
    "                           (kernel_size, kernel_size), \n",
    "                           strides=(1, 1), \n",
    "                           activation='relu',\n",
    "                           padding='same', \n",
    "                           input_shape=(32, 32, 3)))\n",
    "            model.add(MaxPooling2D(pool_size=(pooling_size, pooling_size), \n",
    "                                 strides=(pool_stride, pool_stride))) #сразу следом добавляем слой пулинга\n",
    "            model.add(Dropout(dropout))\n",
    "        else:\n",
    "            # Создание последующих слоев свертки\n",
    "            model.add(Conv2D(filters, \n",
    "                          (kernel_size, kernel_size), \n",
    "                          strides=(1, 1),\n",
    "                          padding='same',\n",
    "                          activation='relu'))\n",
    "            model.add(Conv2D(filters, \n",
    "                          (kernel_size, kernel_size), \n",
    "                          strides=(1, 1),\n",
    "                          padding='same',\n",
    "                          activation='relu'))\n",
    "            model.add(MaxPooling2D(pool_size=(pooling_size, pooling_size), \n",
    "                                strides=(pool_stride, pool_stride)))\n",
    "            model.add(Dropout(dropout))\n",
    "    # Добавление слоя Flatten полносвязной сети\n",
    "    model.add(Flatten())\n",
    "    # Добавление заданного количество скрытых слоев c заданным количеством нейронов\n",
    "    for nodes in dense_layers:\n",
    "        model.add(Dense(nodes, activation='relu'))\n",
    "    # Добавление выходного слоя\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    model.compile(optimizer='adam', \n",
    "                loss='categorical_crossentropy',  \n",
    "                metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "# создаем экземпляр модели для использования с Grid Search\n",
    "model = KerasClassifier(build_fn=create_model, verbose=2)\n",
    "\n",
    "# определяем параметры, которые будут оптимизироваться - добавлены параметры, определяющие конфигурации сверточных слоев и количество и ширину скрытых слоев полносвязной сети\n",
    "hyperparameters = {\n",
    "      'conv_layers': [[(4,5,2,2),(8,3,2,2)],\n",
    "                      [(8,5,2,2),(16,3,2,2)],\n",
    "                      [(32,5,2,2),(64,3,2,2)]],\n",
    "      'dense_layers': [[50],[50,20]],\n",
    "      'epochs':[3, 5, 10],\n",
    "      'batch_size':[64, 128, 256],\n",
    "      'dropout':[0.25,0.5]\n",
    "    }\n",
    "\n",
    "# запускаем Grid Search\n",
    "grid = GridSearchCV(estimator=model, param_grid=hyperparameters, n_jobs=-1, cv=3,verbose=2)\n",
    "grid_result = grid.fit(x_train, y_train)\n",
    "\n",
    "# выводим результаты\n",
    "print(\"Лучший результат: %f с использованием %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "# Сетка работала 2 часа\n",
    "# Лучший результат: 0.721860 с использованием {'batch_size': 128, 'conv_layers': [(32, 5, 2, 2), (64, 3, 2, 2)], 'dense_layers': [50], 'dropout': 0.25, 'epochs': 10}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# проверка работы обученной модели с оптимальными параметрами\n",
    "best_model = create_model([(32, 5, 2, 2), (64, 3, 2, 2)],[50],0.25)\n",
    "best_model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001,amsgrad=True),\n",
    "                   loss='categorical_crossentropy',\n",
    "                   metrics=['accuracy'])\n",
    "\n",
    "\n",
    "best_model.fit(x_train, y_train, batch_size=128, epochs=20,verbose=1) #увеличение кол-ва эпох до 20 дает прирост метрики ~ на 0,05\n",
    "\n",
    "scores = best_model.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])\n",
    "\n",
    "# Test loss: 0.6729810237884521\n",
    "# Test accuracy: 0.7777000069618225"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# проверка работы обученной модели с большим размеров фильтров - пытаемся добиться еще более лучших результатов\n",
    "best_model = create_model([(64, 5, 2, 2), (128, 3, 2, 2)],[50],0.25)\n",
    "best_model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001,amsgrad=True),\n",
    "                   loss='categorical_crossentropy',\n",
    "                   metrics=['accuracy'])\n",
    "\n",
    "\n",
    "best_model.fit(x_train, y_train, batch_size=128, epochs=20,verbose=1)\n",
    "\n",
    "scores = best_model.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])\n",
    "\n",
    "# Test loss: 0.8028334379196167\n",
    "# Test accuracy: 0.7731000185012817"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    В итоге получаем наилучшие результаты при параметрах {'batch_size': 128, 'conv_layers': [(32, 5, 2, 2), (64, 3, 2, 2)], 'dense_layers': [50], 'dropout': 0.25, 'epochs': 10}\n",
    "    Увеличение размера фильтров, количества слоев в полносвязной сети больше вышезаданных не привело к улучшению результатов на тестовой выборке;\n",
    "    Умеренное увеличение количества эпох, и умеренно малый размер батча приводят к улучшению результатов;\n",
    "    Структура сети AlexNet оказалась (свертка-свертка-пулинг-свертка-свертка-пулинг) оказалась оптимальной"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
